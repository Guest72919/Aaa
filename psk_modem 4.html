<!DOCTYPE html> <html lang="en"> <head>   <meta charset="UTF-8">   <meta name="viewport" content="width=device-width, initial-scale=1.0">   <title>14-Tone PSK Modem</title>   <style>     body {       font-family: Arial, sans-serif;       margin: 20px;     }     #fileInput {       margin: 20px 0;     }     canvas {       border: 1px solid #ccc;       margin: 10px 0;     }     button {       margin-top: 20px;       cursor: pointer;       padding: 10px;     }     #progress-container {       margin-top: 20px;       width: 100%;       height: 20px;       background-color: #f3f3f3;       border-radius: 5px;       display: none;     }     #progress-bar {       height: 100%;       width: 0%;       background-color: #4caf50;       border-radius: 5px;     }     .audio-controls {       margin-top: 20px;     }     #audioPlayer {       margin-top: 10px;     }   </style> </head> <body>   <h1>14-Tone PSK Modem</h1>   <input type="file" id="fileInput" accept="audio/*">   <p>Upload an audio file (max duration: 30 minutes)</p>      <div id="progress-container">     <div id="progress-bar"></div>   </div>    <canvas id="waveform" width="800" height="200"></canvas>   <canvas id="fft" width="800" height="200"></canvas>    <button id="downloadBtn" disabled>Download Encoded MP3</button>    <div class="audio-controls">     <button id="playBtn" disabled>Play</button>     <button id="pauseBtn" disabled>Pause</button>     <button id="stopBtn" disabled>Stop</button>   </div>    <audio id="audioPlayer" controls></audio>    <script src="https://cdn.jsdelivr.net/npm/ffmpeg.js/ffmpeg.min.js"></script>   <script>     const fileInput = document.getElementById("fileInput");     const downloadBtn = document.getElementById("downloadBtn");     const playBtn = document.getElementById("playBtn");     const pauseBtn = document.getElementById("pauseBtn");     const stopBtn = document.getElementById("stopBtn");     const audioPlayer = document.getElementById("audioPlayer");     const progressContainer = document.getElementById("progress-container");     const progressBar = document.getElementById("progress-bar");      let audioContext, audioBuffer, encodedSignal, audioBlob, audioUrl, audioElement;      const MAX_DURATION = 30 * 60; // 30 minutes in seconds     const SAMPLE_RATE = 44100; // 44.1kHz sample rate     const BITRATE = 100; // Symbols per second     const CARRIER_FREQUENCY = 1000; // 1kHz carrier     const PHASES = [...Array(14)].map((_, i) => (i * (2 * Math.PI)) / 14); // 14 tones      fileInput.addEventListener("change", async (event) => {       const file = event.target.files[0];       if (!file) return;        if (!audioContext) {         audioContext = new (window.AudioContext || window.webkitAudioContext)();       }        const arrayBuffer = await file.arrayBuffer();       audioBuffer = await audioContext.decodeAudioData(arrayBuffer);        if (audioBuffer.duration > MAX_DURATION) {         alert("Audio file exceeds maximum duration of 30 minutes.");         return;       }        visualizeAudio(audioBuffer);       encodedSignal = encodeToPSK(audioBuffer);       downloadBtn.disabled = false;     });      function visualizeAudio(buffer) {       const waveformCtx = document.getElementById("waveform").getContext("2d");       const fftCtx = document.getElementById("fft").getContext("2d");        // Draw waveform       const channelData = buffer.getChannelData(0);       waveformCtx.clearRect(0, 0, waveformCanvas.width, waveformCanvas.height);       waveformCtx.beginPath();       waveformCtx.strokeStyle = "blue";        const step = Math.ceil(channelData.length / waveformCanvas.width);       for (let i = 0; i < waveformCanvas.width; i++) {         const sample = channelData[i * step];         const y = (1 - sample) * (waveformCanvas.height / 2);         if (i === 0) {           waveformCtx.moveTo(i, y);         } else {           waveformCtx.lineTo(i, y);         }       }       waveformCtx.stroke();        // Draw FFT       const fftResult = fft(channelData.slice(0, 2048));       fftCtx.clearRect(0, 0, fftCanvas.width, fftCanvas.height);       fftCtx.beginPath();       fftCtx.strokeStyle = "red";        for (let i = 0; i < fftResult.length / 2; i++) {         const y = fftResult[i] * fftCanvas.height;         fftCtx.lineTo((i / fftResult.length) * fftCanvas.width, fftCanvas.height - y);       }       fftCtx.stroke();     }      function encodeToPSK(buffer) {       const channelData = buffer.getChannelData(0);       const samplesPerSymbol = Math.floor(SAMPLE_RATE / BITRATE);        // Quantize to 14 tones       const symbols = [];       for (let i = 0; i < channelData.length; i += samplesPerSymbol) {         const avg = channelData.slice(i, i + samplesPerSymbol).reduce((a, b) => a + b, 0) / samplesPerSymbol;         const symbolIndex = Math.floor(((avg + 1) / 2) * PHASES.length);         symbols.push(PHASES[Math.min(symbolIndex, PHASES.length - 1)]);       }        // Generate modulated signal       const signal = new Float32Array(symbols.length * samplesPerSymbol);       symbols.forEach((phase, index) => {         for (let j = 0; j < samplesPerSymbol; j++) {           const t = (index * samplesPerSymbol + j) / SAMPLE_RATE;           signal[index * samplesPerSymbol + j] = Math.sin(2 * Math.PI * CARRIER_FREQUENCY * t + phase);         }       });        return signal;     }      function fft(buffer) {       const fftSize = buffer.length;       const re = new Float32Array(fftSize);       const im = new Float32Array(fftSize);        // Perform FFT (basic implementation)       for (let i = 0; i < fftSize; i++) {         re[i] = buffer[i] * Math.cos((2 * Math.PI * i) / fftSize);         im[i] = buffer[i] * Math.sin((2 * Math.PI * i) / fftSize);       }        return re.map((val, i) => Math.sqrt(val ** 2 + im[i] ** 2));     }      downloadBtn.addEventListener("click", async () => {       if (!encodedSignal) return;        const ffmpeg = await FFmpeg.createFFmpeg({ log: true });        // Show progress bar       progressContainer.style.display = "block";       progressBar.style.width = "0%";        await ffmpeg.load();        const waveBlob = new Blob([new Uint8Array(encodedSignal.buffer)], { type: "audio/wav" });       const waveUrl = URL.createObjectURL(waveBlob);        const response = await fetch(waveUrl);       const arrayBuffer = await response.arrayBuffer();       await ffmpeg.FS("writeFile", "output.wav", new Uint8Array(arrayBuffer));        // Set up progress tracking for FFmpeg       ffmpeg.setProgress(({ ratio }) => {         progressBar.style.width = `${(ratio * 100).toFixed(2)}%`;       });        // Convert WAV to MP3 using libmp3lame codec       await ffmpeg.run("-i", "output.wav", "-acodec", "libmp3lame", "-ab", "192k", "output.mp3");        const mp3Data = ffmpeg.FS("readFile", "output.mp3");       const mp3Blob = new Blob([mp3Data.buffer], { type: "audio/mp3" });       const mp3Url = URL.createObjectURL(mp3Blob);        // Create a downloadable link for the MP3 file       const downloadLink = document.createElement("a");       downloadLink.href = mp3Url;       downloadLink.download = "encoded_audio.mp3";       downloadLink.click();        // Enable audio controls       audioBlob = new Blob([mp3Data.buffer], { type: "audio/mp3" });       audioUrl = URL.createObjectURL(audioBlob);       audioPlayer.src = audioUrl;        playBtn.disabled = false;       pauseBtn.disabled = false;       stopBtn.disabled = false;       audioPlayer.play();     });      playBtn.addEventListener("click", () => {       audioPlayer.play();     });      pauseBtn.addEventListener("click", () => {       audioPlayer.pause();     });      stopBtn.addEventListener("click", () => {       audioPlayer.pause();       audioPlayer.currentTime = 0; // Reset playback to the beginning     });   </script> </body> </html>